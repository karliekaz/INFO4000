{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "from helper_functions import set_seeds\n",
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io,transform\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup path to data folder\n",
    "data_path = Path(\"Mnist_Image_Data/\")\n",
    "\n",
    "train_dir = data_path / \"Images\" / \"train\"\n",
    "test_dir = data_path / \"Images\"/ \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing model with the default (best) available weights\n",
    "# chose resnet 18 since it is generally simple and faster to train - I tried other models but it took way too long to train the model \n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "model = resnet18(weights=weights)\n",
    "model.eval()\n",
    "preprocess = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze the base parameters\n",
    "# freeze all layers so that the model can be used for MNIST dataset - freezing speeds up the training process and prevents overfitting \n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to modify the connected layer so that the model adjusts for the 10 class outputs \n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=3, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#using class from previous MNIST example in info3000 - need to use it to combine the csv file data with the actual picture\n",
    "# also need to normalize data \n",
    "class MNIST():\n",
    "\n",
    "    def __init__(self, dataset, dir, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.dir = dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.dir, self.dataset.iloc[idx, 0]) \n",
    "        img = Image.open(img_name).convert('L')  # Open image in grayscale mode\n",
    "\n",
    "        label = self.dataset.iloc[idx, 1]\n",
    "\n",
    "        # Resizing\n",
    "        img = img.resize((32, 32))\n",
    "\n",
    "        # Applying the transform (if provided)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        img = transforms.ToTensor()(img)\n",
    "        label = torch.tensor(int(label))\n",
    "\n",
    "        return img, label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49000 100\n"
     ]
    }
   ],
   "source": [
    "dataset_path_train = 'Mnist_Image_Data/train.csv'\n",
    "dataset_path_test = 'Mnist_Image_Data/test.csv'\n",
    "\n",
    "train_csv = pd.read_csv(dataset_path_train)\n",
    "test_csv = pd.read_csv(dataset_path_test)\n",
    "\n",
    "train_data = MNIST(dataset=train_csv, dir=train_dir)\n",
    "test_data = MNIST(dataset=test_csv, dir=test_dir)\n",
    "\n",
    "print(train_data.__len__(),test_data.__len__())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io,transform\n",
    "from skimage.color import rgb2gray\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "Shape of Imagetorch.Size([1, 32, 32]) datatype iamge: <class 'torch.Tensor'> datalabel: <class 'torch.Tensor'>\n",
      "(32, 32)\n",
      "torch.Size([])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#used this from INFO3000 example using MNIST \n",
    "\n",
    "# Get image from dataset\n",
    "image1,label1 = train_data.__getitem__(1000)\n",
    "print(type(label1))\n",
    "print(f\"Shape of Image{image1.shape} datatype iamge: {type(image1)} datalabel: {type(label1)}\")\n",
    "image1 = (image1.numpy()).reshape(32,32)\n",
    "\n",
    "# Check the shape of the image\n",
    "print(image1.shape)\n",
    "print(label1.shape)\n",
    "\n",
    "# Display image\n",
    "io.imshow(image1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloaders\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_dataloader:\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 86.0%\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "\n",
    "    for images, labels in test_dataloader:\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on test set: {accuracy}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
